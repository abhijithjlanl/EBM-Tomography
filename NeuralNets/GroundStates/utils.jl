using ITensors
using LinearAlgebra
using StatsBase
using DelimitedFiles
using Flux
GRISE_PATH = "../../Utils/"

include(GRISE_PATH*"MCMC.jl")
include(GRISE_PATH*"Potts_learning.jl")
include(GRISE_PATH*"Py_exporter.jl")
using IterTools:product

include("MPS_sampler.jl")

T= [1 0 ;  1/sqrt(3)   sqrt(2/3) ;
      1/sqrt(3)   sqrt(2/3) *exp(im* 2* pi /3); 1/sqrt(3)   sqrt(2/3) *exp(im* 4* pi /3) ]



MVec = [[T[i,j] for j in 1:2] for i in 1:4]
M = [0.5*reshape(MVec[i], 2,1)* conj(reshape(MVec[i], 1,2)) for i in 1:4]



d = hcat([[tr(M[i]*M[j]) for i in 1:4] for j in 1:4]...)
d_inv =  inv(d)
T_mats = [ sum(d_inv[i,j]*M[j] for j in 1:4 ) for i in 1:4]


function Tetra_POVM(n , out_index ,  out_index_povm)
    #index_list here must be out_index
    T = [1 0 ;  1/sqrt(3)   sqrt(2/3) ;
         1/sqrt(3)   sqrt(2/3) *exp(im* 2* pi /3); 1/sqrt(3)   sqrt(2/3) *exp(im* 4* pi /3) ]
    POVM_LIST = []
    for i in 1:n
        push!(POVM_LIST, ITensor( T, out_index_povm[i] , out_index[i]) )
    end
    return POVM_LIST
end
function Heisen_exact_gs_two_body_states(n_qubits; g =1, J = 1)
    sites = siteinds("S=1/2",n_qubits)
    global ampo = AutoMPO()

    for j=1:n_qubits-1
        global ampo += 0.5g,"S+",j,"S-",j+1
        global ampo += 0.5g,"S-",j,"S+",j+1
        global ampo += J,"Sz",j,"Sz",j+1
    end
    H = MPO(ampo,sites)
    return  DMRG_twobody_states(H, n_qubits)
end



function TIM_exact_gs_two_body_states(n_qubits; g =1,J = 1)
    sites = siteinds("S=1/2",n_qubits)
    global ampo = AutoMPO()
    for j=1:n_qubits-1
        global ampo += 0.5*g,"Sx",j
        global ampo += J,"Sz",j,"Sz",j+1
    end
    global ampo += 0.5*g,"Sx",n_qubits
    H = MPO(ampo,sites)

    return  DMRG_twobody_states(H, n_qubits)
end

function TIM_exact_gs_sampler(n_qubits, n_samples; g =1, J =1,  POVM_fn = Tetra_POVM, q = 4)
    sites = siteinds("S=1/2",n_qubits)
    global ampo = AutoMPO()
    for j=1:n_qubits-1
        global ampo += 0.5*g,"Sx",j
        global ampo += J,"Sz",j,"Sz",j+1
    end
    global ampo += 0.5*g,"Sx",n_qubits
    H = MPO(ampo,sites)

    return  DMRG_exact_sampler( H ,n_qubits,  n_samples ; POVM_fn = POVM_fn, q = q)
end
function Heisen_exact_gs_sampler(n_qubits, n_samples; g =1, J =1,  POVM_fn = Tetra_POVM, q = 4)
    @warn "Heisenberg hamiltonian has two ground states connected by parity"
    sites = siteinds("S=1/2",n_qubits)
    global ampo = AutoMPO()

    for j=1:n_qubits-1
        global ampo += 0.5*g,"S+",j,"S-",j+1
        global ampo += 0.5*g,"S-",j,"S+",j+1
        global ampo += J,"Sz",j,"Sz",j+1
    end
    H = MPO(ampo,sites)

    return  DMRG_exact_sampler( H ,n_qubits,  n_samples ; POVM_fn = POVM_fn, q = q)
end


function DMRG_exact_sampler( H ,n_qubits,  n_samples ; POVM_fn = Tetra_POVM, q = 4, cutoff = 1E-10)
    
#    sites = [x[1] for x in siteinds(H, plev=0)]
    sites = [inds(x, tags= "Site", plev = 0)[1] for x in H]
    sweeps = Sweeps(50) # number of sweeps is 5
    maxdim!(sweeps,10,20,100,100,200,300,400) # gradually increase states kept
    cutoff!(sweeps,cutoff) # desired truncation error

    psi0 = randomMPS(sites,2)
    energy,psi = dmrg(H,psi0,sweeps)
    return POVM_exact_sampler(psi, n_samples, POVM_fn, q)
end


function POVM_exact_sampler(psi, n_samples, POVM_fn, q)

    """
Samples from the distribution generated by the POVM. Only works if the POVM corresponds to rank 1 matrices
    """
    n_qubits = length(psi)
    out_index = siteinds(psi)
    out_index_povm = [Index(4, tags = "POVM,Site,n=$i") for i in 1:n_qubits]
    POVM_LIST =  POVM_fn(n_qubits , out_index ,  out_index_povm)
    [psi[i] = psi[i]*POVM_LIST[i] for i in 1:n_qubits]
    orthogonalize!(psi,1)
    psi[1] = psi[1]/norm(psi)
    return [ITensors.sample(psi) for _ in ProgressBar(1:n_samples)]
end







function DMRG_twobody_states(H, n_qubits, cutoff = 1E-10)
  
   # sites = [x[1] for x in siteinds(H, plev=0)]
    sites = [inds(x, tags= "Site", plev = 0)[1] for x in H]
    sweeps = Sweeps(50) # number of sweeps 
    maxdim!(sweeps,10,20,100,100,200,300,400) # gradually increase states kept
    cutoff!(sweeps,cutoff) # desired truncation error

    psi0 = randomMPS(sites,2)
    energy,psi = dmrg(H,psi0,sweeps)
    out_index = siteinds(psi)
    one_body= Dict()
    two_body= Dict()
    psidag =  dag(psi)
    prime!(psidag, "Link")
    for i in 1:n_qubits
        prime!(psidag[i], "Site")
        rho =  psi[1]*psidag[1]
        for k in 2:n_qubits
            rho *= psi[k]*psidag[k]
        end
        mat =  reshape( array( rho), 2,2)
        one_body[(i)] = mat/tr(mat) 
        noprime!(psidag[i],"Site")
    end

    for i in 1:n_qubits, j in  i+1:n_qubits
        prime!(psidag[i], "Site")
        prime!(psidag[j], "Site")
        rho =  psi[1]*psidag[1]
        for k in 2:n_qubits
            rho *= psi[k]*psidag[k]
        end
        rinds = inds(rho)
        @assert rinds[1].id == rinds[2].id; "Order is wrong, 1 and 2 must be at same site"
        @assert rinds[1].plev ==  rinds[3].plev == 0; " 1 and 3, must be unprimed"
        newinds = [rinds[1], rinds[3], rinds[2], rinds[4] ]
        mat =  reshape( Array( rho, newinds...), 4,4)
        two_body[(i,j)] = mat/tr(mat) 
        noprime!(psidag[i],"Site")
        noprime!(psidag[j],"Site")
    end

    return one_body, two_body
end


function Tetra_POVM(n , out_index ,  out_index_povm)
    #index_list here must be out_index
    T = [1 0 ;  1/sqrt(3)   sqrt(2/3) ;
 1/sqrt(3)   sqrt(2/3) *exp(im* 2* pi /3); 1/sqrt(3)   sqrt(2/3) *exp(im* 4* pi /3) ]
    POVM_LIST = []
    for i in 1:n
        push!(POVM_LIST, ITensor( T, out_index_povm[i] , out_index[i]) )
    end
    return POVM_LIST

end


function Amplitude_list(n, POVM_LIST, MPS_LIST)
        #Make sure that the POVM and MPS have the same
        # Indicis so that they contract properly
        #Z =  real(normalize(n, MPS_LIST).store)[1]
        #Psi =  contract(n, MPS_LIST)
        A = []
        for i in 1:n
            push!(A, MPS_LIST[i]*POVM_LIST[i])
        end

        return A
end



function MCMC_sampler(n, q,  n_samples, AMPLITUDE_LIST, out_index_povm; burn_in = 10000)
    
    #Prob_lookup = Dict{}()
    state = Int.(ones(n))
    state_list = []
    for t in 1:burn_in
        for i in 1:n
            p = conditional(i,q, state, AMPLITUDE_LIST, out_index_povm)
            state[i] =  wsample(1:q, p )
            #print(state)
        end
    end
    println("burnin complete")
    for t in 1:n_samples
        for i in 1:n
            p = conditional(i,q, state, AMPLITUDE_LIST, out_index_povm)
            state[i] =  wsample(1:q, p )
        end
        push!(state_list, state[:])
        if t%(n_samples/100) < 100/n_samples
            a =  (t/(n_samples/100))
            print(" $a % complete \r")
        end

    end
    return state_list

end
prob(x) =  abs(x)^2

function conditional(u, q,  state,  AMPLITUDE_LIST, out_index_povm)
        n = length(AMPLITUDE_LIST)
        indices =  deleteat!(collect(1:n), u)

        A =  AMPLITUDE_LIST[u]
        for i in indices
            A =  A*AMPLITUDE_LIST[i]*setelt(out_index_povm[i]( state[i] ) )

        end
        #P =  ( prob.(A)/ (A* dag(A)).store[1])
        P =  prob.(A)
        return  real.(P.store)

end

function MCMC_sampler_blocked(n, q,  n_samples, AMPLITUDE_LIST, out_index_povm; block_size=3, burn_in=10000)
    #Prob_lookup = Dict{}()
    state = Int.(ones(n))
    state_list = []
    #Create a blocked amplitude tensor list for easy computation of probabilitites
    BLOCK_LIST = []
    global A
    for i in 1:n
        if i%block_size == 1
            A =  AMPLITUDE_LIST[i]
        end
        if i%block_size != 1
            A =  AMPLITUDE_LIST[i]*A
        end
        if ( floor(i/block_size) > 0 && i%block_size==0) || i ==n
            push!(BLOCK_LIST, A)
        end
    end
for t in 1:burn_in
        for i in 1:n
            p = conditional_blocked(i,q, state, BLOCK_LIST, out_index_povm, block_size)
            state[i] =  wsample(1:q, p )
        end

        if t%(burn_in/100) < 100/burn_in
            a =  (t/(burn_in/100))
            print(" Burnin $a % complete \r")
        end
    end

    println("burnin complete")
    for t in 1:n_samples
        for i in 1:n

                p = conditional_blocked(i,q, state, BLOCK_LIST, out_index_povm,  block_size)

            state[i] =  wsample(1:q, p )
        end
        push!(state_list, state[:])
        if t%(n_samples/100) < 100/n_samples
            a =  (t/(n_samples/100))
            print(" $a % complete \r")
        end
    end
    return state_list

end



function conditional_blocked(u, q,  state,  BLOCK_LIST, out_index_povm, block_size)
        n = length(state)
        indices =  deleteat!(collect(1:n), u)

        B = BLOCK_LIST[1]
        c = 0
        counter =  zeros( Int(ceil(n/block_size)) + 1)
        for i in 1:n
            if ( c>0 && floor(i/block_size) == c && counter[c] ==0)
                counter[c] +=1
                B =  B*BLOCK_LIST[ Int(floor( (i)/block_size) + 1) ]
            end
            if i in indices
                B =  B*setelt(out_index_povm[i]( state[i] ) )
            end
            c =  Int(floor(i/block_size))

        end
        P =  prob.(B)
        return  real.(P.store)

end

function two_body_reduced_states_from_samples(est_samples)
    ##Given samples return first four body reduced states

    n_samples_est = length(est_samples)
    n_qubits =  length(est_samples[1])
    ds = countmap(est_samples)
    one_body_dist = Dict()
    two_body_dist = Dict()
    for i in 1:n_qubits
        one_body_dist[(i)] = zeros(4)
        for j in i+1:n_qubits
            two_body_dist[(i,j)] =  zeros(4,4)
        end
    end

    for (k,v) in ds
        for i in 1:n_qubits
            one_body_dist[(i)][k[i]] +=  v/n_samples_est
            for j in i+1:n_qubits
                two_body_dist[(i,j)][k[i],k[j]] += v/n_samples_est
            end
        end


     end
    one_body= Dict()
    two_body= Dict()

    A =    Base.Iterators.product(repeat([1:4],2)...)
    for i in 1:n_qubits
        one_body[(i)] =  sum(T_mats[t]*one_body_dist[(i)][t] for t in 1:4) 
        for j in i+1:n_qubits
            two_body[(i,j)] =  sum( kron(T_mats[k[1]],T_mats[k[2]])*two_body_dist[(i,j)][k[1], k[2]]  for k in A) 
        end
    end

    return one_body, two_body
end


function NN_learn_reduced_error(n_qubits, n_samples, exact_reduced_states; n_est_samples=10000, activation_list =  [swish, swish,swish, identity])
    run(`python learn_sample_err.py $n_qubits $n_samples`)
    path_list= []
    for i in 1:n_qubits
        push!(path_list, "saved_model/model$i.h5" )
        path =  "saved_model/model$i.h5"
    end
        H =  load_model(path_list, activation_list)
    #    [Check_NN_correctness[H[i]] for i in 1:n_qubits]
    est_samples = Gibbs_sampler(n_qubits,4 ,n_est_samples , 10000, H)
    (one_body, two_body) = two_body_reduced_states_from_samples(est_samples)
    one_err_list = [tr_norm(one_body[(i)] -  exact_reduced_states[1][(i)]) for i in 1:n_qubits  ] 
    mean_one_err =  mean(one_err_list)
    max_one_err =  max(one_err_list...)
    two_err_list = [tr_norm(two_body[k] -  exact_reduced_states[2][k]) for k in keys(two_body)] 
    mean_two_err = mean(two_err_list)
    max_two_err =  max(two_err_list...)
    return mean([mean_one_err,mean_two_err]), max(max_one_err, max_two_err)

end

function NN_learn_reduced_states(n_qubits, n_samples; n_est_samples=10000, init_state = 0,
     activation_list =  [swish, swish,swish, identity], args = [])
    if length(args) == 0
        run(`python learn_sample_err.py $n_samples $n_qubits`)
    else 
        run(`python learn_sample_err.py $n_samples $n_qubits $(args[1]) $(args[2]) $(args[3]) $(args[4]) $(args[5]) $(args[6])`)
       # @show Cmd(["python learn_sample_err.py $n_samples $n_qubits "*"$args"[2:end-1]])
       # run(Cmd(["python learn_sample_err.py $n_samples $n_qubits "*"$args"[2:end-1]]) )

    end
    path_list= []
    for i in 1:n_qubits
        push!(path_list, "saved_model/model$i.h5" )
        path =  "saved_model/model$i.h5"
    end
    H =  load_model(path_list, activation_list)
    #    [Check_NN_correctness[H[i]] for i in 1:n_qubits]
    if init_state == 0
        init_state = Int.(ones(n_qubits))
    end

    est_samples = Gibbs_sampler(n_qubits,4 ,n_est_samples , 40000, H, init_state = init_state)
    (one_body, two_body) = two_body_reduced_states_from_samples(est_samples)
    return one_body, two_body
    end





σZ = [ 1 0; 0 -1 ]
σX = [0 1; 1 0]


function Z_basis_dict(two_body_reduced)
    ZZ_vals = deepcopy(two_body_reduced)
    for (k,v) in two_body_reduced
        if length(k) == 2
            ZZ_vals[k] = tr( kron(σZ, σZ)*v)
        elseif length(k) == 1
            ZZ_vals[k] = tr(σZ* v)
        end
      end
    return ZZ_vals
    end



function t_test(x; conf_level=0.95)
    alpha = (1 - conf_level)
    tstar = quantile(TDist(length(x)-1), 1 - alpha/2)
    SE = std(x)/sqrt(length(x))
   return  tstar * SE
  end

function dict_error(rd1, rd2)
    v_arr =  [rd1[k] - rd2[k] for k  in keys(rd1)]
    k_arr =  [keys(rd1)...]
    return Dict(zip(k_arr, v_arr))
end
tr_norm(M) =  sum( abs.(eigvals(M)) )
op_norm(M) =  max( abs.(eigvals(M))... )
max_arr(x) = max(x...)

function ZZ_err(M)
    if size(M)[1] == 2
        return abs(tr(σZ* M))
        end
    if size(M)[1] == 4
        return abs(tr(kron(σZ, σZ)*M))
        end
    end

function dist_measure(one_err, two_err;aggregator = mean, mat_norm = tr_norm )
        one_err_arr = [mat_norm(one_err[k]) for k in keys(one_err) ]
        two_err_arr = [mat_norm(two_err[k]) for k in keys(two_err) ]
        return aggregator( [ one_err_arr..., two_err_arr...])
end





